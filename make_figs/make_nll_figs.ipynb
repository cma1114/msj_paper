{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import *\n",
    "from visualizations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwoc_fa_suffix = \"_ft_0to31_interleaved_stdmixsafecombonarafa_none_mult0_629\"\n",
    "ftwoc_path = \"cackerman/ft_randalias_0to31_interleaved_stdmixsafecombo6_none_mult0\"\n",
    "ftwocsuffix = \"_\" + ftwoc_path.replace(\"/checkpoint-\",\"_\").replace(\"cackerman/\",\"\") + \"_654\" \n",
    "basesuffix = \"_untunedmodel_new\"\n",
    "nll_dir=\"./nlls_ftwoc_narafa/\"\n",
    "plot_data = []\n",
    "names = ['Harmful1']\n",
    "for i, test_responses_str in enumerate(['harmful3_responses']):\n",
    "    nlls_mean_by_type,nlls_vars_by_type={},{}\n",
    "    resptype = test_responses_str.split(\"_\")[0]\n",
    "    if \"_lat_\" in test_responses_str: resptype += \"_LAT\"\n",
    "\n",
    "    responses_dict = np.load(f'{nll_dir}{test_responses_str}{basesuffix}_0.npy', allow_pickle=True).item()\n",
    "    nlls_mean_by_type2 = responses_dict['means']\n",
    "    nlls_vars_by_type2 = responses_dict['vars']\n",
    "    nlls_mean_by_type[\"Untuned\"]=nlls_mean_by_type2[\"raw\"]\n",
    "    nlls_vars_by_type[\"Untuned\"]=nlls_vars_by_type2[\"raw\"]\n",
    "\n",
    "    responses_dict = np.load(f'{nll_dir}{test_responses_str}_alias{basesuffix}_0.npy', allow_pickle=True).item()\n",
    "    nlls_mean_by_type2 = responses_dict['means']\n",
    "    nlls_vars_by_type2 = responses_dict['vars']\n",
    "    nlls_mean_by_type[\"Untuned + Sanit.\"]=nlls_mean_by_type2[\"raw\"]\n",
    "    nlls_vars_by_type[\"Untuned + Sanit.\"]=nlls_vars_by_type2[\"raw\"]\n",
    "    \n",
    "    responses_dict = np.load(f'{nll_dir}{test_responses_str}{ftwoc_fa_suffix}_0.npy', allow_pickle=True).item()\n",
    "    nlls_mean_by_type2 = responses_dict['means']\n",
    "    nlls_vars_by_type2 = responses_dict['vars']\n",
    "    nlls_mean_by_type[\"Fine Tuned\"]=nlls_mean_by_type2[\"raw\"]\n",
    "    nlls_vars_by_type[\"Fine Tuned\"]=nlls_vars_by_type2[\"raw\"]\n",
    "\n",
    "    responses_dict = np.load(f'{nll_dir}{test_responses_str}_alias{ftwoc_fa_suffix}_0.npy', allow_pickle=True).item()\n",
    "    nlls_mean_by_type2 = responses_dict['means']\n",
    "    nlls_vars_by_type2 = responses_dict['vars']\n",
    "    nlls_mean_by_type[\"Fine Tuned + Sanit.\"]=nlls_mean_by_type2[\"raw\"]\n",
    "    nlls_vars_by_type[\"Fine Tuned + Sanit.\"]=nlls_vars_by_type2[\"raw\"]\n",
    "        \n",
    "    title=names[i]\n",
    "    #title = f\"{resptype.capitalize()}\"\n",
    "    if \"_alias\" in test_responses_str: title += \": Sanitized\"\n",
    "    plot_data.append((\"\", list(range((responses_dict['counts'].shape[0]))), nlls_mean_by_type, nlls_vars_by_type, 4))\n",
    " \n",
    "    \n",
    "plot_grid_new(plot_data, n_cols=2, save_path=f\"nlls_{ftwoc_fa_suffix[1:]}_{test_responses_str}.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
